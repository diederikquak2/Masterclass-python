{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Practices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll put into practice what we've learned so far by working with some real-world data. Let's begin with loading a log of sports activities of a single person:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_df = pd.read_json('data/activities.json', convert_dates=['start_date_local'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Simple and Useful DataFrame Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question__: What does this overview tell us at a first glance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    activity_df\n",
    "    .sort_values('start_date_local', ascending=False)\n",
    "    .head(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_df['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_df['type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_df['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(activity_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question__: in evaluation of the above expression, is any `DataFrame` method called?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separation of Concerns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume we want to create a process that reads such activities from file, selects all the running activities, sorts these by date, and saves the result in another file. A possible implementation may look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_activities():\n",
    "    activity_df = pd.read_json('data/activities.json', convert_dates=['start_date_local'])\n",
    "    runs_sorted_by_date_df = (\n",
    "        activity_df\n",
    "        .loc[lambda df: df['type'] == 'Run']\n",
    "        .sort_values('start_date_local')\n",
    "    )\n",
    "    runs_sorted_by_date_df.to_csv('data/processed_activities.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_activities()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion**:\n",
    "\n",
    "- What if there are many of these processes, and the data source changes from .json file to database?\n",
    "- How can we test the business logic without access to a file system or database?\n",
    "- How can this be improved?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm data/processed_activities.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As soon as our work shifts from pure exploratory analysis in a notebook to repeatable and robust production systems, separation of concerns becomes important. As discussed above, any code that combines business logic with side effects such as reading/writing data, handling user input from a GUI, etc, can easily break when there are any changes in infrastructure or user interaction.\n",
    "\n",
    "The example in the cells below shows how our naive process implementation is improved by abstracting the infrastructure and separating the business logic from the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infrastructure Layer\n",
    "class ActivitySource(ABC):\n",
    "    @abstractmethod\n",
    "    def load(self):\n",
    "        pass\n",
    "\n",
    "@dataclass\n",
    "class JsonLocalActivitySource(ActivitySource):\n",
    "    filename: str = 'data/activities.json'  # will usually come from a config file\n",
    "    \n",
    "    def load(self):\n",
    "        return pd.read_json(self.filename, convert_dates=['start_date_local'])\n",
    "\n",
    "@dataclass\n",
    "class PostgressActivitySource(ActivitySource):\n",
    "    db_connection: Any  # will usually come from a config file\n",
    "    \n",
    "    def load(self):\n",
    "        # pseudo-code\n",
    "        return db_connection.query('SELECT * FROM activities')\n",
    "\n",
    "class ActivitySink(ABC):\n",
    "    @abstractmethod\n",
    "    def save(self, activity_df: pd.DataFrame):\n",
    "        pass\n",
    "\n",
    "@dataclass\n",
    "class CsvLocalActivitySink(ActivitySink):\n",
    "    filename: str = 'data/processed_activities.csv'  # will usually come from a config file\n",
    "    \n",
    "    def save(self, activity_df: pd.DataFrame):\n",
    "        activity_df.to_csv(self.filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Business Layer\n",
    "def select_runs_and_sort_by_date(activity_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return (\n",
    "        activity_df\n",
    "        .loc[lambda df: df['type'] == 'Run']\n",
    "        .sort_values('start_date_local')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Layer\n",
    "def process_activities(\n",
    "    source: ActivitySource,\n",
    "    processing_fn: Callable[[pd.DataFrame], pd.DataFrame],\n",
    "    sink: ActivitySink\n",
    ") -> None:\n",
    "    sink.save(processing_fn(source.load()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_activities(JsonLocalActivitySource(), select_runs_and_sort_by_date, CsvLocalActivitySink())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: for large/complex workflows, consider tools such as [Apache Airflow](https://airflow.apache.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decluttering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_df['year'] = activity_df['start_date_local'].dt.year\n",
    "activity_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pandas.pydata.org/pandas-docs/stable/user_guide/basics.html#dt-accessor\n",
    "https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#time-date-components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities_2018_df = activity_df.loc[activity_df['year'] == 2018]\n",
    "activities_2018_by_type = activities_2018_df.groupby('type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_velocity_by_type = activities_2018_by_type['velocity_mean'].mean()\n",
    "mean_velocity_by_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_df = pd.read_json('data/activities.json', convert_dates=['start_date_local'])\n",
    "(\n",
    "    activity_df\n",
    "    .loc[lambda df: df['start_date_local'].dt.year == 2018]\n",
    "    .groupby('type')['velocity_mean'].mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introducing ... `Groupby.transform()`, TODO link to docs of agg/transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    activity_df\n",
    "    .loc[lambda df: df['start_date_local'].dt.year == 2018]\n",
    "    .groupby('type')['velocity_mean'].transform('mean')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    activity_df\n",
    "    .loc[lambda df: df['start_date_local'].dt.year == 2018]\n",
    "    .assign(v_mean_diff=lambda df: (\n",
    "        df.groupby('type')['velocity_mean']\n",
    "        .transform(lambda type_v: type_v - type_v.mean())))\n",
    "    .sample(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Readable, Testable Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_non_warmup(activity_df):\n",
    "    return (\n",
    "        (activity_df['elapsed_time'] > 600) |\n",
    "        (activity_df['heartrate_mean'] > 150)\n",
    "    )\n",
    "\n",
    "def select_non_warmup_runs(activity_df):\n",
    "    return (\n",
    "        activity_df\n",
    "        .loc[is_non_warmup]\n",
    "        .loc[lambda df: df['type'] == 'Run']\n",
    "    )\n",
    "\n",
    "def to_z_score(series):\n",
    "    # What if series has a lenght of 1?\n",
    "    return (series - series.mean()) / series.std()\n",
    "\n",
    "def add_z_score(activity_df, column):\n",
    "    return activity_df.assign(**{f'{column}_z': lambda df: to_z_score(df[column])})\n",
    "\n",
    "def best_n_years(activity_df, metrics=['velocity_mean'], n_years=1):\n",
    "    return (\n",
    "        activity_df\n",
    "        .assign(year=lambda df: df['start_date_local'].dt.year)\n",
    "        .groupby('year')[metrics].mean()\n",
    "        .sort_values(metrics, ascending=False)\n",
    "        .head(n_years)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    activity_df\n",
    "    .pipe(select_non_warmup_runs)\n",
    "    .pipe(add_z_score, column='velocity_mean')\n",
    "    .pipe(best_n_years, metrics=['velocity_mean_z', 'velocity_mean'], n_years=5)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Discussion__: Is this a reliable analysis? Which question does it answer? What can be improved?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Don't Repeat Yourself](https://en.wikipedia.org/wiki/Don%27t_repeat_yourself)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "from functools import wraps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.DEBUG)  # You may need to restart the notebook to make this work\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.warning(f'There are {len(activity_df)} activities in the DataFrame')\n",
    "logger.debug(f'If this line is not visible, restart the notebook kernel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise__: Create a decorator that logs the number of rows and columns of the DataFrame that is passed to the pipeline functions above. You can use the `@skip_None` and `@check_value` decorators of the previous module as examples.\n",
    "\n",
    "__Bonus Exercise__: Extend this decorator such that it also logs the same information about the DataFrame that is returned by the pipeline function.\n",
    "\n",
    "__Bonus Exercise__: Extend this decorator such that it also logs how many rows are missing for each column. The [`isnull()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.isnull.html) method and `sum()` built-in function may be helpful for this purpose.\n",
    "\n",
    "__Bonus Exercise__: Extend this decorator such that it also logs how much time it took to call the decorated pipeline function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/pipe_logging.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the longest run per year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/longest_run_per_year.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the average (mean) number of hours spent cycling by weekday? It is ok to ignore the days without activity (i.e. these don't need to be counted as 0 for the mean)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/hours_cycling_by_weekday.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the 10 longest time gaps between activities? The method [`diff()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.diff.html) may be useful for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/longest_time_gaps.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the 7-day periods with the highest total amount of activity (in hours)? Similar to `groupby()`, Pandas has a method [`rolling()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.rolling.html) for using an (aggregating) sliding window. It can even use a flexible time-based window size, given that the DataFrame index is a datetime-like (and sorted)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pd.DataFrame({'a': range(5), 'b': range(5, 10)})\n",
    "    .rolling(3).mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pd.DataFrame({'a': range(5), 'b': range(5, 10)})\n",
    "    .rolling(3, min_periods=1).mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/total_time_7days.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe the 20 or 30 runs with highest mean heartrate. Looking at the name and distance, do you see some common pattern? Looking at other columns such as velocity_mean, do you see any activities that are out of the ordinary? Can it be that there are outliers based on measurement errors?\n",
    "\n",
    "Try to create an analysis that detects runs with an uncommon combination of mean heartrate and mean velocity, for example, by comparing z values. If you're familiar with Scikit-Learn, consider using one of its outlier detection methods or fitting a (linear) regression and looking for large residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_df.sort_values('heartrate_mean', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
